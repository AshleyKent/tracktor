{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tracktor as tr\n",
    "import sys\n",
    "import cv2\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from scipy.spatial.distance import cdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of individuals in tracked video\n",
    "n_inds = 5\n",
    "\n",
    "# offset to be added based on toxtrac arena selection\n",
    "offset_x = 100 # fish - 0; flume - 245; spider - 75; termite - 370; mouse - 85; tadpole - 45; zebrafish - 100\n",
    "offset_y = 0 # fish - 0; flume - 0; spider - 0; termite - 0; mouse - 12; tadpole - 0; zebrafish - 0\n",
    "\n",
    "# name of source video and paths\n",
    "video = 'zebrafish_video'\n",
    "input_vidpath = '/Users/vivekhsridhar/Documents/Code/Python/OpenCV/tracktor/videos/' + video + '.mp4'\n",
    "output_vidpath = '/Users/vivekhsridhar/Documents/Code/Python/OpenCV/tracktor/output/' + video + '_compared.mp4'\n",
    "tracktor_datapath = '/Users/vivekhsridhar/Documents/Code/Python/OpenCV/tracktor/output/' + video + '_tracked.csv'\n",
    "toxtrack_datapath = '/Users/vivekhsridhar/Documents/Code/Python/OpenCV/tracktor/output/' + video + '_toxtracked.txt'\n",
    "idtrack_datapath = '/Users/vivekhsridhar/Documents/Code/Python/OpenCV/tracktor/output/' + video + '_idtracked.txt'\n",
    "codec = 'DIVX' # try other codecs if the default doesn't work ('DIVX', 'avc1', 'XVID') note: this list is non-exhaustive\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:20: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Open video\n",
    "cap = cv2.VideoCapture(input_vidpath)\n",
    "if cap.isOpened() == False:\n",
    "    sys.exit('Video file cannot be read! Please check input_vidpath to ensure it is correctly pointing to the video file')\n",
    "\n",
    "## Open datafiles\n",
    "df1 = pd.read_csv(tracktor_datapath)\n",
    "df2 = pd.read_table(toxtrack_datapath, header=None, index_col=False, names=['frame', 'arena', 'id', 'pos_x', 'pos_y'])\n",
    "df3 = pd.DataFrame({'pos_x':[], 'pos_y':[], 'id':[]})\n",
    "\n",
    "df_tmp = pd.read_table(idtrack_datapath)\n",
    "col_del = 'Unnamed: ' + str(n_inds*3)\n",
    "df_tmp = df_tmp.drop(labels=col_del, axis=1)\n",
    "\n",
    "for i in range(n_inds):\n",
    "    tmp = df_tmp.iloc[:,3*i:3*(i+1)]\n",
    "    tmp = tmp.rename(index=str, columns={'X'+str(i+1):'pos_x', 'Y'+str(i+1):'pos_y', 'ProbId'+str(i+1):'id'})\n",
    "    tmp['id'] = i\n",
    "    tmp['frame'] = np.arange(tmp.shape[0])\n",
    "    df3 = pd.concat([df3, tmp])"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 38,
=======
   "execution_count": 9,
>>>>>>> 8d5eb2269e45f0cb9dd9369393646702b2d9662e
=======
   "execution_count": 9,
>>>>>>> 8d5eb2269e45f0cb9dd9369393646702b2d9662e
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
<<<<<<< HEAD
<<<<<<< HEAD
     "execution_count": 38,
=======
     "execution_count": 9,
>>>>>>> 8d5eb2269e45f0cb9dd9369393646702b2d9662e
=======
     "execution_count": 9,
>>>>>>> 8d5eb2269e45f0cb9dd9369393646702b2d9662e
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Video writer class to output video with contour and centroid of tracked object(s)\n",
    "# make sure the frame size matches size of array 'final'\n",
    "fourcc = cv2.VideoWriter_fourcc(*codec)\n",
    "output_framesize = (int(cap.read()[1].shape[1]),int(cap.read()[1].shape[0]))\n",
    "out = cv2.VideoWriter(filename = output_vidpath, fourcc = fourcc, fps = 30.0, frameSize = output_framesize, isColor = True)\n",
    "last = 0\n",
    "\n",
    "while(True):\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    this = cap.get(1)\n",
    "    if ret == True:\n",
    "        frame = cv2.resize(frame, None, fx = 1.0, fy = 1.0, interpolation = cv2.INTER_LINEAR)\n",
    "        \n",
    "        if df1[df1['frame'] == this].empty == False:\n",
    "            x1 = df1[df1['frame'] == this]['pos_x']\n",
    "            y1 = df1[df1['frame'] == this]['pos_y']\n",
    "            for pts1 in range(0,len(x1)):\n",
    "                cv2.circle(frame, (int(x1.values[pts1]),int(y1.values[pts1])), 7, (100,255,255), -1, cv2.LINE_AA)\n",
    "        if df2[df2['frame'] == this].empty == False:\n",
    "            x2 = df2[df2['frame'] == this]['pos_x']+offset_x\n",
    "            y2 = df2[df2['frame'] == this]['pos_y']+offset_y\n",
    "            for pts2 in range(0,len(x2)):\n",
    "                cv2.circle(frame, (int(x2.values[pts2]),int(y2.values[pts2])), 5, (100,100,255), -1, cv2.LINE_AA)\n",
    "        if df3[df3['frame'] == this].empty == False:\n",
    "            x3 = df3[df3['frame'] == this]['pos_x']\n",
    "            y3 = df3[df3['frame'] == this]['pos_y']\n",
    "            for pts3 in range(0,len(x3)):\n",
    "                if np.isnan(x3.values[pts3]) == False:\n",
    "                    cv2.circle(frame, (int(x3.values[pts3]),int(y3.values[pts3])), 4, (255,100,100), -1, cv2.LINE_AA)\n",
    "        \n",
    "        # Add legend\n",
    "        cv2.circle(frame, (20,20), 7, (100,255,255), -1, cv2.LINE_AA)\n",
    "        cv2.putText(frame, '- Tracktor', (35,25), font, 0.4, (255,255,255), 1, cv2.LINE_AA)\n",
    "        \n",
    "        cv2.circle(frame, (20,50), 5, (100,100,255), -1, cv2.LINE_AA)\n",
    "        cv2.putText(frame, '- ToxTrac', (35,55), font, 0.4, (255,255,255), 1, cv2.LINE_AA)\n",
    "        \n",
    "        cv2.circle(frame, (20,80), 4, (255,100,100), -1, cv2.LINE_AA)\n",
    "        cv2.putText(frame, '- IDTracker', (35,85), font, 0.4, (255,255,255), 1, cv2.LINE_AA)\n",
    "        \n",
    "        cv2.putText(frame, str(int(this)), (5,output_framesize[1] - 20), font, 1, (255,255,255), 2)\n",
    "        \n",
    "        # Display the resulting frame\n",
    "        out.write(frame)\n",
    "        cv2.imshow('frame', frame)\n",
    "        if cv2.waitKey(1) == 27:\n",
    "            break\n",
    "        \n",
    "    if last == this:\n",
    "        break\n",
    "    \n",
    "    last = this\n",
    "\n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Last frame detected by each software 15000.0 14969 14998.0 ---\n",
      "--- Tracktor performed with an accuracy of  0.9998000133324445 ---\n",
      "--- ToxTrac performed with an accuracy of  0.7855876274915006 ---\n",
      "--- IDTracker performed with an accuracy of  0.914032397840144 ---\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy (this measure is meaningless for tracktor since tracktor forces detections)\n",
    "# Hence, accuracy for our software was determined as true detection rate determined by manual observations\n",
    "nframes = max(np.max(df1['frame']),np.max(df2['frame']),np.max(df3['frame']))+1\n",
    "acc_1 = (len(df1) - sum(np.isnan(df1['pos_x'])))/(n_inds*nframes)\n",
    "acc_2 = (len(df2) - sum(np.isnan(df2['pos_x'])))/(n_inds*nframes)\n",
    "acc_3 = (len(df3) - sum(np.isnan(df3['pos_x'])))/(n_inds*nframes)\n",
    "\n",
    "print('--- Last frame detected by each software', np.max(df1['frame']), np.max(df2['frame']), np.max(df3['frame']), '---')\n",
    "print('--- Tracktor performed with an accuracy of ', acc_1, '---')\n",
    "print('--- ToxTrac performed with an accuracy of ', acc_2, '---')\n",
    "print('--- IDTracker performed with an accuracy of ', acc_3, '---')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
