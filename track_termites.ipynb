{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tracktor as tr\n",
    "import cv2\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from scipy.spatial.distance import cdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## Global parameters\n",
    "# colours is a vector of BGR values which are used to identify individuals in the video\n",
    "# t_id is termite id and is also used for individual identification\n",
    "# number of elements in colours should be greater than n_inds (THIS IS NECESSARY FOR VISUALISATION ONLY)\n",
    "# number of elements in t_id should be greater than n_inds (THIS IS NECESSARY TO GET INDIVIDUAL-SPECIFIC DATA)\n",
    "n_inds = 8\n",
    "t_id = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H']\n",
    "colours = [(0,0,255),(0,255,255),(255,0,255),(255,255,255),(255,255,0),(255,0,0),(0,255,0),(0,0,0)]\n",
    "\n",
    "# this is the block_size and offset used for adaptive thresholding\n",
    "# these values are critical for tracking performance\n",
    "block_size = 51\n",
    "offset = 20\n",
    "\n",
    "# minimum area and maximum area occupied by the animal in number of pixels\n",
    "# this parameter is used to get rid of other objects in view that might be hard to threshold out but are differently sized\n",
    "min_area = 500\n",
    "max_area = 10000\n",
    "\n",
    "# mot determines whether the tracker is being used in noisy conditions to track a single object or for multi-object\n",
    "# using this will enable k-means clustering to force n_inds number of animals\n",
    "mot = True\n",
    "\n",
    "# in this example, we use a circular mask to ignore area outside the petri-dish\n",
    "# mask_offset represents offset of circle from centre of the frame\n",
    "mask_offset_x = -18\n",
    "mask_offset_y = -5\n",
    "\n",
    "# name of source video\n",
    "video = 'termite_video'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-f53c280d99fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'frame'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m27\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## Path to source video\n",
    "cap = cv2.VideoCapture(\"/Users/viveksridhar/Documents/Code/Python/OpenCV/tracktor/videos/\" + video + \".MP4\")\n",
    "\n",
    "## Video writer class to output video with contour and centroid of tracked object(s)\n",
    "# make sure the frame size matches size of array 'final'\n",
    "fourcc = cv2.VideoWriter_fourcc(*'avc1')\n",
    "out = cv2.VideoWriter(filename = video + '.mp4', fourcc = fourcc, fps = 60.0, frameSize = (1920, 1080), isColor = True)\n",
    "\n",
    "## Individual location(s) measured in the last and current step\n",
    "meas_last = list(np.zeros((n_inds,2)))\n",
    "meas_now = list(np.zeros((n_inds,2)))\n",
    "\n",
    "df = []\n",
    "last = 0\n",
    "\n",
    "while(True):\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    this = cap.get(1)\n",
    "    if ret == True:\n",
    "        # Preprocess the image for background subtraction\n",
    "        frame = cv2.resize(frame, None, fx = 1.0, fy = 1.0, interpolation = cv2.INTER_LINEAR)\n",
    "        thresh = tr.colour_to_thresh(frame, block_size, offset)\n",
    "\n",
    "        # Apply mask to ignore area outside the petri dish\n",
    "        mask = np.zeros(thresh.shape)\n",
    "        cv2.circle(mask, (mask.shape[1]//2 + mask_offset_x, mask.shape[0]//2 + mask_offset_y), 520, 255, -1)\n",
    "        thresh[mask == 0] = 0\n",
    "        \n",
    "        # Custom background subtraction\n",
    "        bg = thresh.copy()\n",
    "        cv2.circle(bg, (bg.shape[1]//2 + mask_offset_x, bg.shape[0]//2 + mask_offset_y), 520, 0, -1)\n",
    "        bgsub = thresh - bg\n",
    "        \n",
    "        final, contours, meas_last, meas_now = tr.detect_and_draw_contours(frame, thresh, meas_last, meas_now, min_area, max_area)\n",
    "        if len(meas_now) != n_inds:\n",
    "            contours, meas_now = tr.apply_k_means(contours, n_inds, meas_now)\n",
    "        \n",
    "        row_ind, col_ind = tr.hungarian_algorithm(meas_last, meas_now)\n",
    "        final, meas_now, df = tr.reorder_and_draw(final, colours, n_inds, col_ind, meas_now, df, mot, this)\n",
    "        \n",
    "        # Create output dataframe\n",
    "        for i in range(n_inds):\n",
    "            df.append([this, meas_now[i][0], meas_now[i][1], t_id[i]])\n",
    "        \n",
    "        # Display the resulting frame\n",
    "        out.write(final)\n",
    "        cv2.imshow('frame', final)\n",
    "        if cv2.waitKey(1) == 27:\n",
    "            break\n",
    "            \n",
    "    if last == this:\n",
    "        break\n",
    "    \n",
    "    last = this\n",
    "\n",
    "## Write positions to file\n",
    "df = pd.DataFrame(np.matrix(df), columns = ['frame','pos_x','pos_y', 'id'])\n",
    "df.to_csv(video + '.csv', sep=',')\n",
    "\n",
    "## When everything done, release the capture\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
